# Bankâ€‘FraudÂ Analysis

> **Detect â€¢ Explain â€¢ Prevent**  
> Machineâ€‘learning pipeline for spotting fraudulent banking transactions

---

## ğŸ“‘ Project overview
Financial institutions process millions of transactions every day, and even a tiny fraud rate can translate into massive losses.  
This repository walks through the **full dataâ€‘science cycle**:

1. Load and explore the raw dataset (EDA).  
2. Clean data & engineer meaningful features.  
3. Tackle class imbalance, train and compare several models.  
4. Evaluate metrics and interpret top drivers of fraud.  
5. Export a readyâ€‘toâ€‘use pipeline that can be served in production.

Everything lives in a single, reproducible Jupyter notebook: `bank_fraud.ipynb`.

---

## ğŸ—‚ï¸ Repository layout
```
â”‚  README.md            # youâ€™re reading it ğŸ‰
â”‚  bank_fraud.ipynb     # main notebook with code + commentary
â”œâ”€ data/                # raw & processed datasets (empty in Git for GDPR)
â”œâ”€ models/              # exported models / pipelines (.pkl)
â””â”€ images/              # EDA plots, confusion matrices, SHAP charts
```
*Folders `data/`,Â `models/`, `images/` are created automatically on first run.*

---

## ğŸš€ Quick start
```bash
# 1 â€” clone the repo
git clone https://github.com/AlidarxD/bank_fraud_analysis.git
cd bank_fraud_analysis

# 2 â€” (optional) create a virtual env
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3 â€” install dependencies
pip install -r requirements.txt

# 4 â€” launch Jupyter
jupyter lab   # or jupyter notebook
```
Open `bank_fraud.ipynb` and run cells top â†’ bottom.

---

## ğŸ› ï¸ Tech stack
| Category              | Tools |
|-----------------------|-------|
| Core language         | **PythonÂ 3.11** |
| Data wrangling        | `pandas`,Â `numpy` |
| ML & imbalance        | `scikitâ€‘learn`,Â `imbalancedâ€‘learn` |
| Visualisation         | `matplotlib`,Â `seaborn` |
| Notebooks             | `JupyterÂ Lab` |

Full list â†’ `requirements.txt`.

---

## ğŸ” Dataset
The demo uses the public **CreditÂ Card Fraud Detection** dataset (Kaggle).  
Each row represents a transaction; the target is column `Class` (1Â =Â fraud,Â 0Â =Â legit). All features were standardised via PCA, so the data are anonymised and GDPRâ€‘safe.

> *Using a different dataset?*  Adjust column names in the *DataÂ Loading* section of the notebook.

---

## ğŸ“Š Baseline vs tuned results
| Model                | ROCâ€‘AUC | Recall (fraud) | Precision (fraud) |
|----------------------|:------:|:--------------:|:-----------------:|
| LogisticÂ Regression  | 0.92 | 0.81 | 0.76 |
| RandomÂ Forest        | **0.97** | **0.90** | 0.88 |
| GradientÂ Boosting    | 0.96 | 0.88 | **0.89** |

**RandomÂ Forest** achieves the best recall/precision tradeâ€‘off and is selected as the final model.

---

## ğŸ“ˆ Next steps
* ğŸ¯ **Hyperparameter search**Â with Optuna / Hyperopt.  
* ğŸ§© **Explainability**Â via SHAP or LIME for deeper insight.  
* ğŸŒ **FastAPI wrapper**Â â†’ REST endpoint for realâ€‘time scoring.  
* ğŸ“‰ **Monitoring**Â â€” dataâ€‘drift & modelâ€‘decay reports in production.

PRs and feature requests are welcome!

---

## âš ï¸ Disclaimer
This repository is educational. **Do not deploy the model to production asâ€‘is** without additional legal checks, security hardening and live monitoring.

